# LibreChat Configuration for GCP Vertex AI Model Garden + Judge0 Code Interpreter
# Judge0 integration is built-in to Code Interpreter (no MCP needed)

version: 1.3.1

cache: true

# Model Specs - Quick Access to SOTA Models
# These appear as individual items in the model selector for instant access
modelSpecs:
  enforce: false      # Don't force modelSpecs - allow normal endpoints too
  prioritize: false   # Don't auto-select modelSpecs - allow endpoint selection
  list:
    # DeepSeek R1 - Advanced reasoning
    - name: "deepseek-r1"
      label: "DeepSeek R1"
      description: "Advanced reasoning model - excels at complex problem solving and deep analysis"
      iconURL: "/assets/deepseek.svg"
      showIconInMenu: true
      showIconInHeader: true
      preset:
        endpoint: "Vertex-AI"
        model: "deepseek-r1"

    # Qwen3 Thinking - Shows reasoning process
    - name: "qwen3-thinking"
      label: "Qwen3 Next 80B Thinking"
      description: "Thinking mode - shows detailed reasoning process step-by-step"
      iconURL: "/assets/qwen.svg"
      showIconInMenu: true
      showIconInHeader: true
      preset:
        endpoint: "Vertex-AI"
        model: "qwen3-thinking"

    # Llama 4 Maverick - Creative innovation
    - name: "llama-4-maverick"
      label: "Llama 4 Maverick 17B"
      description: "Early preview - creative problem solving and innovation"
      iconURL: "/assets/llama.svg"
      showIconInMenu: true
      showIconInHeader: true
      preset:
        endpoint: "Vertex-AI"
        model: "llama-4-maverick"

interface:
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  # Agent Marketplace - enables internal agent sharing
  peoplePicker:
    users: true      # Allow selecting specific users when sharing agents
    groups: true     # Allow selecting groups
    roles: true      # Allow selecting roles (e.g., all admins)
  marketplace:
    use: true        # Enable the agent marketplace UI

registration:
  socialLogins: ['github', 'google', 'discord', 'openid']

endpoints:
  custom:
    # GCP Vertex AI Models via Custom OAuth2 Proxy
    - name: 'Vertex-AI'
      apiKey: 'dummy'  # Not used - authentication handled by vertex-proxy
      baseURL: 'http://vertex-proxy:4000'
      iconURL: 'assets/vertex-ai.svg'  

      models:
        default:
          - 'deepseek-r1'
          - 'deepseek-v3'
          - 'deepseek-ocr'
          - 'minimax-m2'
          - 'qwen3-235b'
          - 'llama-3.3-70b'
          - 'qwen3-thinking'
          - 'llama-4-maverick'
          - 'llama-4-scout'
        fetch: false

      titleConvo: true
      titleModel: 'deepseek-v3'
      modelDisplayLabel: 'GCP Vertex AI'

      # Don't drop parameters - let the proxy handle them
      dropParams: []

    # Mistral AI
    - name: 'Mistral'
      apiKey: '${MISTRAL_API_KEY}'
      baseURL: 'https://api.mistral.ai/v1'

      models:
        default:
          - 'mistral-large-latest'
          - 'mistral-medium-latest'
          - 'mistral-small-latest'
          - 'codestral-latest'
        fetch: true

      titleConvo: true
      titleModel: 'mistral-small-latest'
      modelDisplayLabel: 'Mistral'

      # Mistral requires dropping these parameters to avoid 422 errors
      dropParams: ['stop', 'user', 'frequency_penalty', 'presence_penalty']

    # Perplexity AI
    - name: 'Perplexity'
      apiKey: '${PERPLEXITY_API_KEY}'
      baseURL: 'https://api.perplexity.ai'

      models:
        default:
          - 'sonar'                    # Lightweight search (127k context)
          - 'sonar-pro'                # Advanced search (200k context)
          - 'sonar-reasoning'          # Real-time reasoning with search (127k)
          - 'sonar-reasoning-pro'      # DeepSeek-R1 powered reasoning (127k)
          - 'sonar-deep-research'      # Long-form research reports
        fetch: false

      titleConvo: true
      titleModel: 'sonar'
      modelDisplayLabel: 'Perplexity'

    # OpenRouter - Access to many models via single API
    - name: 'OpenRouter'
      apiKey: '${OPENROUTER_KEY}'
      baseURL: 'https://openrouter.ai/api/v1'

      models:
        default:
          - 'google/gemma-3-4b-it:free'
          - 'meta-llama/llama-3.2-3b-instruct:free'
          - 'mistralai/mistral-7b-instruct:free'
          - 'deepseek/deepseek-chat-v3-0324:free'
        fetch: true

      titleConvo: true
      titleModel: 'google/gemma-3-4b-it:free'
      modelDisplayLabel: 'OpenRouter'

      dropParams: ['stop']

    # HuggingFace Inference API
    - name: 'HuggingFace'
      apiKey: '${HUGGINGFACE_TOKEN}'
      baseURL: 'https://api-inference.huggingface.co/v1'

      models:
        default: []
        fetch: true

      titleConvo: true
      titleModel: 'meta-llama/Llama-3.2-3B-Instruct'
      modelDisplayLabel: 'HuggingFace'

# Web Search Configuration
# Enables web search capabilities for AI agents
webSearch:
  # Search Provider: SearXNG (NO API KEY NEEDED!)
  # Self-hosted metasearch engine running in Docker
  # Both api and searxng containers are on the same Docker network
  searxngInstanceUrl: '${SEARXNG_URL}'

  # Content Scraper: Serper (FREE TIER: 2,500 calls/month)
  # Sign up at https://serper.dev for API key
  serperApiKey: '${SERPER_API_KEY}'
  searchProvider: 'serper'

  # Content Scraper: Also using Serper (supports both search and scraping)
  scraperProvider: 'serper'
  scraperTimeout: 10000  # 10 seconds timeout

  # Reranker: Disabled (using OpenAI for embeddings instead)
  # jinaApiKey: '${JINA_API_KEY}'
  # rerankerType: 'jina'

  # Safe search level: 0 (off), 1 (moderate), 2 (strict)
  safeSearch: 1

# NOTE: Judge0 Code Execution is integrated directly into the Code Interpreter
# No MCP configuration needed! Just click the Code Interpreter button and enter your RapidAPI key.
# Get FREE RapidAPI key: https://rapidapi.com/judge0-official/api/judge0-ce

# Model Context Protocol (MCP) Servers
# Extends LibreChat with external tools and capabilities
mcpServers:
  # EXA AI Search - DISABLED (npm packages don't have working executables)
  # All tested packages fail: exa-mcp-server, @199bio/exa-mcp-server, hosted SSE
  # TODO: Find working EXA MCP server implementation or wait for official package fix
  # exa:
  #   type: stdio
  #   command: npx
  #   args:
  #     - -y
  #     - "@199bio/exa-mcp-server"
  #   env:
  #     EXA_API_KEY: ${EXA_API_KEY}
  #   timeout: 60000
  #   initTimeout: 15000

  # Serper - Google Search API for real-time search results
  # Get FREE API key at: https://serper.dev (2,500 calls/month free)
  # Features: Google search with filters, news search, image search
  serper:
    type: stdio
    command: npx
    args:
      - -y
      - serper-search-scrape-mcp-server
    env:
      SERPER_API_KEY: ${SERPER_API_KEY}
    timeout: 30000  # 30 seconds timeout
    initTimeout: 10000
